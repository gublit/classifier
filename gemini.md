# Gemini Code Assist Project Configuration

This file provides context to the Gemini Code Assist model to improve its accuracy and efficiency when working on this project.

## Project Overview

This project is a binary classification task focused on predicting customer responses for a bank marketing campaign. It utilizes Python with libraries such as scikit-learn, pandas, and seaborn. The primary goal is to train, evaluate, and save various classification models.

## File and Directory Structure

-   `main.py`: The main Python script for data preprocessing, model training, evaluation, and saving artifacts.
-   `dataset/`: Contains the core dataset (`bank.csv`) 
-   `notebooks/`: Jupyter notebooks used for exploratory data analysis (EDA), initial model prototyping, and visualization.
-   `plots/`: Stores output visualizations, such as correlation matrices and ROC curves, generated by the script.
-   `environment.yaml`: The Conda environment file, which contains all the necessary dependencies to ensure a reproducible setup.
-   `saved_models/`: A directory that may contain final or production-ready model artifacts and is the designated location for saving trained models, encoders, and pipelines (`.pkl` files).

## Commands

-   **Install dependencies:** `conda env create -f environment.yaml`
-   **Run the main script:** `python main.py`
-   **Run linter (example):** `ruff check .`

## Coding Conventions and Style

-   **Style Guide:** Adhere to the PEP 8 style guide for Python code.
-   **Artifacts:** All generated artifacts (models, encoders, pipelines) should be saved to the `saved_models/` directory to ensure consistency.
-   **Clarity:** Ensure code is well-commented, especially the data preprocessing and model evaluation steps.
-   **Dependencies:** Add any new dependencies to the `environment.yaml`.