{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb681ff5",
   "metadata": {},
   "source": [
    "This notebook is designed for tabular classification tasks with pandas and scikit-learn.\n",
    "It is a simple example of how to use pandas and scikit-learn to build a classification model using a tabular dataset. The code includes data preprocessing, model training, and evaluation steps.\n",
    "The dataset used in this example is the bank marketing dataset from the UCI Machine Learning Repository. The dataset contains information about a bank's marketing campaign and whether or not a customer subscribed to a term deposit.\n",
    "The goal is to predict whether a customer will subscribe to a term deposit based on their demographic and behavioral features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91399d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                                roc_auc_score, roc_curve,auc)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "notebook_path = Path.cwd()\n",
    "file_path = notebook_path.parent / 'dataset' / 'bank.csv'\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "data = pd.read_csv(file_path, header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e789dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_n_change(data):\n",
    "    # Rename columns for better readability\n",
    "    data.rename(columns={\n",
    "        'marital':'marital_status',\n",
    "        'default':'credit_default',\n",
    "        'housing':'housing_loan',\n",
    "        'loan':'personal_loan',\n",
    "        'y':'response'}, inplace=True)\n",
    "    #change data types for faster loading\n",
    "    data['response'] = data['response'].astype('category')\n",
    "    data['marital_status'] = data['marital_status'].astype('category')\n",
    "    data['education'] = data['education'].astype('category')\n",
    "    data['job'] = data['job'].astype('category')\n",
    "    data['contact'] = data['contact'].astype('category')\n",
    "    data['month'] = data['month'].astype('category')\n",
    "    data['day'] = data['day'].astype('category')\n",
    "    data['credit_default'] = data['credit_default'].astype('category')\n",
    "    data['housing_loan'] = data['housing_loan'].astype('category')\n",
    "    data['personal_loan'] = data['personal_loan'].astype('category')\n",
    "    return data\n",
    "data=rename_n_change(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a551bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['poutcome'].value_counts(dropna=False)/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f68fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop poutcome with more than 80% unknown values\n",
    "data.drop('poutcome', axis=1, inplace=True)"
   ]
  },
    {
   "cell_type": "markdown",
   "id": "9ab84ac5",
   "metadata": {},
   "source": [
    "Determine if data is imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['response'].value_counts().plot(kind='bar', color=['#FF9999', '#66B3FF'])\n",
    "plt.title('Distribution of Response Variable')\n",
    "plt.xlabel('Response')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31151b5b",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis with Seaborn\n",
    "Visualize the data with Seaborn to understand the distribution of features and the relationship between features\n",
    "and the target variable."
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "sns.set_style('whitegrid')\n",
    "sns.pairplot(data,hue='response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "data['housing_loan'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Housing Loan')\n",
    "plt.xlabel('Housing Loan')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix for numeric features\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_ft = data[['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']]\n",
    "corr_matrix = numeric_ft.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a463e1",
   "metadata": {},
   "source": [
    "Assign features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(columns=['response'])\n",
    "y=data['response']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,stratify=y,random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbcf42",
   "metadata": {},
   "source": [
    "Apply Preprocessing to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5956434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical features\n",
    "numeric_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_features = ['job', 'marital_status', 'education', 'month', 'housing_loan', 'personal_loan', 'contact', 'credit_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b706feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer to apply different preprocessing steps to different columns\n",
    "pre_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "# Create a pipeline that first applies the preprocessor and then fits a classifier\n",
    "pre_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', pre_processor)\n",
    "])"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fff263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1908c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessing on training data and transform both sets\n",
    "X_train = pre_pipeline.fit_transform(X_train)\n",
    "X_test = pre_pipeline.transform(X_test)  # No fitting on test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a192fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train,y_train = smote.fit_resample(X_train, y_train) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf7fb3",
   "metadata": {},
   "source": [
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06006c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate and train\n",
    "logreg=LogisticRegression(class_weight= 'balanced')\n",
    "dtree=DecisionTreeClassifier()\n",
    "rforest=RandomForestClassifier(class_weight= 'balanced',n_estimators=100)\n",
    "gbm=GradientBoostingClassifier()\n",
    "gnb=GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "xgb=XGBClassifier()\n",
    "lgbm=LGBMClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d376cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict, Evaluate and plot\n",
    "models = {\"Logistic Regression\": logreg, \"Decision Tree\": dtree, \"Random Forest\": rforest, \"Gradient Boosting\": gbm, \"Gaussian Naive Bayes\": gnb, \"K Neighbors\": knn, \"XGBoost\": xgb, \"LightGBM\": lgbm}\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'ROC_AUC_Score'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    new_row = pd.DataFrame([{'Model': name, 'Accuracy': accuracy, 'ROC_AUC_Score': roc_auc}])\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the results by ROC_AUC_Score in descending order\n",
    "results = results.sort_values(by='ROC_AUC_Score', ascending = False,ignore_index = True)\n",
    "# Display the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80453959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(logreg, '../saved_models/logreg_model.pkl')\n",
    "joblib.dump(dtree, '../saved_models/dtree_model.pkl')\n",
    "joblib.dump(rforest, '../saved_models/rforest_model.pkl')\n",
    "joblib.dump(gbm, '../saved_models/gbm_model.pkl')\n",
    "joblib.dump(gnb, '../saved_models/gnb_model.pkl')\n",
    "joblib.dump(knn, '../saved_models/knn_model.pkl')\n",
    "joblib.dump(xgb, '../saved_models/xgb_model.pkl')\n",
    "joblib.dump(lgbm, '../saved_models/lgbm_model.pkl')\n",
    "joblib.dump(pre_pipeline, '../saved_models/pre_pipeline.pkl')\n",
    "joblib.dump(label_encoder, '../saved_models/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5260cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "logreg_ = joblib.load('../saved_models/logreg_model.pkl')\n",
    "dtree_ = joblib.load('../saved_models/dtree_model.pkl')\n",
    "rforest_ = joblib.load('../saved_models/rforest_model.pkl')\n",
    "gbm_ = joblib.load('../saved_models/gbm_model.pkl')\n",
    "gnb_ = joblib.load('../saved_models/gnb_model.pkl')\n",
    "knn_ = joblib.load('../saved_models/knn_model.pkl')\n",
    "xgb_ = joblib.load('../saved_models/xgb_model.pkl')\n",
    "lgbm_ = joblib.load('../saved_models/lgbm_model.pkl')\n",
    "pre_pipeline_ = joblib.load('../saved_models/pre_pipeline.pkl')\n",
    "label_encoder_ = joblib.load('../saved_models/label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [30],\n",
    "    'balance': [1000],\n",
    "    'day': [15],\n",
    "    'duration': [200],\n",
    "    'campaign': [1],\n",
    "    'pdays': [999],\n",
    "    'previous': [0],\n",
    "    'job': ['admin.'],\n",
    "    'contact': ['cellular'],\n",
    "    'marital_status': ['single'],\n",
    "    'education': ['university.degree'],\n",
    "    'month': ['may'],\n",
    "    'housing_loan': ['yes'],\n",
    "    'personal_loan': ['no'],\n",
    "    'credit_default': ['no']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0518e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the new data\n",
    "new_d = pd.DataFrame(pre_pipeline_.transform(new_data), columns=pre_pipeline_.get_feature_names_out()) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ddf635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "logreg_pred = logreg_.predict(new_d)\n",
    "dtree_pred = dtree_.predict(new_d)\n",
    "rforest_pred = rforest_.predict(new_d)\n",
    "gbm_pred = gbm_.predict(new_d)\n",
    "gnb_pred = gnb_.predict(new_d)\n",
    "knn_pred = knn_.predict(new_d)\n",
    "xgb_pred = xgb_.predict(new_d)\n",
    "lgbm_pred = lgbm_.predict(new_d)\n",
    "# Print the predictions\n",
    "print(\"Logistic Regression Prediction: \", logreg_pred)\n",
    "print(\"Decision Tree Prediction: \", dtree_pred)\n",
    "print(\"Random Forest Prediction: \", rforest_pred)\n",
    "print(\"Gradient Boosting Prediction: \", gbm_pred)\n",
    "print(\"Gaussian Naive Bayes Prediction: \", gnb_pred)\n",
    "print(\"K Neighbors Prediction: \", knn_pred)\n",
    "print(\"XGBoost Prediction: \", xgb_pred)\n",
    "print(\"LightGBM Prediction: \", lgbm_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}