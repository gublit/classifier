{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified Bank Marketing Analysis and Prediction\n",
    "This notebook provides a comprehensive analysis of the bank marketing dataset. The goal is to predict whether a customer will subscribe to a term deposit. The process includes:\n",
    "1. **Data Loading and Initial Exploration:** Loading the dataset and getting a first look at the data.\n",
    "2. **Data Cleaning and Preprocessing:** Cleaning column names, converting data types, and dropping irrelevant columns.\n",
    "3. **Exploratory Data Analysis (EDA):** Visualizing the data to understand feature distributions and relationships.\n",
    "4. **Feature Engineering and Preprocessing Pipeline:** Creating a robust pipeline for scaling numeric features and encoding categorical features.\n",
    "5. **Handling Class Imbalance:** Using SMOTE to address the imbalance in the target variable.\n",
    "6. **Model Training and Evaluation:** Training and evaluating a suite of classification models.\n",
    "7. **Results and Visualization:** Comparing model performance using accuracy, ROC AUC scores, and ROC curves.\n",
    "8. **Model Saving and Prediction:** Saving the best model and demonstrating its use for predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = Path.cwd()\n",
    "file_path = notebook_path.parent / 'dataset' / 'bank.csv'\n",
    "print(f\"Loading data from: {file_path}\")\n",
    "data = pd.read_csv(file_path, header=0, sep=';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_and_clean(data):\n",
    "    # Rename columns for better readability\n",
    "    data.rename(columns={\n",
    "        'marital':'marital_status',\n",
    "        'default':'credit_default',\n",
    "        'housing':'housing_loan',\n",
    "        'loan':'personal_loan',\n",
    "        'y':'response'}, inplace=True)\n",
    "    # Change data types for faster loading and memory efficiency\n",
    "    for col in ['response', 'marital_status', 'education', 'job', 'contact', 'month', 'day', 'credit_default', 'housing_loan', 'personal_loan']:\n",
    "        data[col] = data[col].astype('category')\n",
    "    # Drop poutcome (many unknowns) and duration (data leakage)\n",
    "    data.drop(['poutcome', 'duration'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "data = rename_and_clean(data)\n",
    "print(\"Data cleaned and preprocessed.\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the response variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=data, x='response')\n",
    "plt.title('Distribution of Response Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical features\n",
    "categorical_features_for_plot = ['job', 'marital_status', 'education', 'month', 'housing_loan', 'personal_loan', 'contact', 'credit_default']\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, variable in enumerate(categorical_features_for_plot, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.countplot(data=data, x=variable, order=data[variable].value_counts().index)\n",
    "    plt.title(f'{variable} Distribution')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric features\n",
    "numeric_ft = data.select_dtypes(include=np.number)\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = numeric_ft.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['response'])\n",
    "y = data['response']\n",
    "\n",
    "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "pre_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "pre_pipeline = Pipeline(steps=[('preprocessor', pre_processor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Splitting and Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=78)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "X_train_processed = pre_pipeline.fit_transform(X_train)\n",
    "X_test_processed = pre_pipeline.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=78)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', random_state=78),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=78),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=78),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=78),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"K Neighbors\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(random_state=78, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(class_weight='balanced', random_state=78)\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'ROC_AUC_Score'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Convert data to dense for Gaussian Naive Bayes\n",
    "    if name == \"Gaussian Naive Bayes\":\n",
    "        X_train_to_fit = X_train_resampled.toarray()\n",
    "        X_test_to_predict = X_test_processed.toarray()\n",
    "    else:\n",
    "        X_train_to_fit = X_train_resampled\n",
    "        X_test_to_predict = X_test_processed\n",
    "\n",
    "    model.fit(X_train_to_fit, y_train_resampled)\n",
    "    y_pred = model.predict(X_test_to_predict)\n",
    "    y_pred_proba = model.predict_proba(X_test_to_predict)[:,1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    new_row = pd.DataFrame([{'Model': name, 'Accuracy': accuracy, 'ROC_AUC_Score': roc_auc}])\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sorted = results.sort_values(by='ROC_AUC_Score', ascending=False, ignore_index=True)\n",
    "print(\"Model Performance Comparison:\")\n",
    "results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Model Saving and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_sorted.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "model_save_path = notebook_path.parent / 'saved_models'\n",
    "model_save_path.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, model_save_path / 'best_model.pkl')\n",
    "joblib.dump(pre_pipeline, model_save_path / 'preprocessing_pipeline.pkl')\n",
    "joblib.dump(label_encoder, model_save_path / 'label_encoder.pkl')\n",
    "\n",
    "print(f\"Best model '{best_model_name}' and preprocessing pipeline saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading the model and making a prediction\n",
    "loaded_model = joblib.load(model_save_path / 'best_model.pkl')\n",
    "loaded_pipeline = joblib.load(model_save_path / 'preprocessing_pipeline.pkl')\n",
    "loaded_label_encoder = joblib.load(model_save_path / 'label_encoder.pkl')\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'age': [42],\n",
    "    'job': ['management'],\n",
    "    'marital_status': ['married'],\n",
    "    'education': ['tertiary'],\n",
    "    'credit_default': ['no'],\n",
    "    'balance': [2000],\n",
    "    'housing_loan': ['yes'],\n",
    "    'personal_loan': ['no'],\n",
    "    'contact': ['cellular'],\n",
    "    'day': [5],\n",
    "    'month': ['may'],\n",
    "    'campaign': [1],\n",
    "    'pdays': [-1],\n",
    "    'previous': [0]\n",
    "})\n",
    "\n",
    "# Ensure categorical columns are of type 'category' to match training\n",
    "for col in categorical_features:\n",
    "    new_data[col] = new_data[col].astype('category')\n",
    "\n",
    "new_data_processed = loaded_pipeline.transform(new_data)\n",
    "prediction_encoded = loaded_model.predict(new_data_processed)\n",
    "prediction = loaded_label_encoder.inverse_transform(prediction_encoded)\n",
    "\n",
    "print(f\"Prediction for new data: {prediction[0]}\")"
   ]
}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}