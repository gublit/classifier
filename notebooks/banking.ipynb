{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f1b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                            roc_auc_score, roc_curve,auc)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ad466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/tisinr/MEGA/Dev/models/classifier/dataset/bank.csv',header=0, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b40ffc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_n_change(data):\n",
    "    # Rename columns for better readability\n",
    "    data.rename(columns={\n",
    "        'marital':'marital_status',\n",
    "        'default':'credit_default',\n",
    "        'housing':'housing_loan',\n",
    "        'loan':'personal_loan',\n",
    "        'y':'target'}, inplace=True)\n",
    "    #change data types\n",
    "    data['target'] = data['target'].astype('category')\n",
    "    data['marital_status'] = data['marital_status'].astype('category')\n",
    "    data['education'] = data['education'].astype('category')\n",
    "    data['job'] = data['job'].astype('category')\n",
    "    data['contact'] = data['contact'].astype('category')\n",
    "    data['month'] = data['month'].astype('category')\n",
    "    data['day'] = data['day'].astype('category')\n",
    "    data['credit_default'] = data['credit_default'].astype('category')\n",
    "    data['housing_loan'] = data['housing_loan'].astype('category')\n",
    "    data['personal_loan'] = data['personal_loan'].astype('category')\n",
    "    return data\n",
    "data=rename_n_change(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea00549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign features and labels\n",
    "X=data.drop(columns=['target'])\n",
    "y=data['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06475acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply preprocessing steps to the dataset\n",
    "# Create a pipeline for preprocessing\n",
    "numeric_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categorical_features = ['job', 'marital_status', 'education', 'month', 'housing_loan', 'personal_loan', 'credit_default']\n",
    "# Create a column transformer to apply different preprocessing steps to different columns\n",
    "pre_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "# Create a pipeline that first applies the preprocessor and then fits a classifier\n",
    "pre_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', pre_processor)\n",
    "])\n",
    "\n",
    "#Split the data into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,stratify=y,random_state=78)\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82022b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit preprocessing on training data and transform both sets\n",
    "X_train = pre_pipeline.fit_transform(X_train)\n",
    "X_test = pre_pipeline.transform(X_test)  # No fitting on test data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6516844",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train ,y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "530f0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare Models\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "dtree = DecisionTreeClassifier()\n",
    "rforest = RandomForestClassifier(n_estimators=100,class_weight='balanced')\n",
    "gbm = GradientBoostingClassifier()\n",
    "svc = SVC(class_weight='balanced',probability=True)\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5138466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = [\n",
    "    ('Logistic Regression', logreg),\n",
    "    ('Decision Tree', dtree),\n",
    "    ('Random Forest', rforest),\n",
    "    ('Gradient Boosting', gbm),\n",
    "    ('Support Vector', svc),\n",
    "    ('Gaussian Naive Bayes', gnb),\n",
    "    ('K Neighbors', knn)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b22786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through models and train\n",
    "for model_name, model in models:\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predicted probabilities\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_roc(X_train, y_train, X_test, y_test, models):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for multiple models in a single figure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train \n",
    "    y_train\n",
    "    X_test \n",
    "    y_test\n",
    "    models\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot diagonal line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "    \n",
    "    # Iterate through models and train\n",
    "    for model_name, model in models:\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predicted probabilities\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic - Model Comparison')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig('roc_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    #Print results\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(y_test,y_pred))\n",
    "    print(\"Classification Report: \\n\",classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67f79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Helper function to train a single model and compute ROC metrics.\n",
    "    \"\"\"\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "    \n",
    "    return model_name, fpr, tpr, roc_auc, metrics\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b09670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_roc(X_train, y_train, X_test, y_test, models, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Plot ROC curves for multiple models in a single figure using parallel processing.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : array-like, training features\n",
    "    y_train : array-like, training target\n",
    "    X_test : array-like, test features\n",
    "    y_test : array-like, test target\n",
    "    models : list of tuples, each containing (model_name, model_instance)\n",
    "    n_jobs : int, number of parallel jobs (-1 uses all available cores)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None (displays the plot and prints metrics)\n",
    "    \"\"\"\n",
    "    # Parallelize model training\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(train_model)(model_name, model, X_train, y_train, X_test, y_test)\n",
    "        for model_name, model in models\n",
    "    )\n",
    "    \n",
    "    # Initialize plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
    "\n",
    "\n",
    "    # Plot ROC curves and print metrics\n",
    "    for model_name, fpr, tpr, roc_auc, metrics in results:\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        # Print metrics for each model\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"Confusion Matrix:\\n\", metrics['confusion_matrix'])\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, metrics['confusion_matrix'].argmax(axis=1)))\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic - Model Comparison')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save and close plot\n",
    "    plt.savefig('roc_comparison.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c80090e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('K Neighbors',\n",
       " array([0.        , 0.05685661, 0.10695053, 0.15266124, 0.19912336, 0.25735755,\n",
       "        1.        ]),\n",
       " array([0.        , 0.34310019, 0.56521739, 0.71266541, 0.77504726, 0.84593573,\n",
       "        1.        ]),\n",
       " np.float64(0.8289053908971572),\n",
       " {'confusion_matrix': array([[6766, 1219],\n",
       "         [ 304,  754]]),\n",
       "  'classification_report': {'0': {'precision': 0.957001414427157,\n",
       "    'recall': 0.8473387601753287,\n",
       "    'f1-score': 0.8988375954832282,\n",
       "    'support': 7985.0},\n",
       "   '1': {'precision': 0.382159148504815,\n",
       "    'recall': 0.7126654064272212,\n",
       "    'f1-score': 0.4975255691191026,\n",
       "    'support': 1058.0},\n",
       "   'accuracy': 0.8315824394559328,\n",
       "   'macro avg': {'precision': 0.669580281465986,\n",
       "    'recall': 0.780002083301275,\n",
       "    'f1-score': 0.6981815823011654,\n",
       "    'support': 9043.0},\n",
       "   'weighted avg': {'precision': 0.8897468399114169,\n",
       "    'recall': 0.8315824394559328,\n",
       "    'f1-score': 0.8518854641227013,\n",
       "    'support': 9043.0}}})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model_name, model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83d2ac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "Confusion Matrix:\n",
      " [[6613 1372]\n",
      " [ 218  840]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9043, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[43mmodels_roc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[26], line 36\u001b[0m, in \u001b[0;36mmodels_roc\u001b[0;34m(X_train, y_train, X_test, y_test, models, n_jobs)\u001b[0m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfusion_matrix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Customize plot\u001b[39;00m\n",
      "\u001b[1;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/clasfi/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[1;32m    214\u001b[0m         )\n",
      "\u001b[1;32m    215\u001b[0m     ):\n",
      "\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[1;32m    226\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/clasfi/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2671\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n",
      "\u001b[1;32m   2563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n",
      "\u001b[1;32m   2564\u001b[0m \n",
      "\u001b[1;32m   2565\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   2667\u001b[0m \u001b[38;5;124;03m<BLANKLINE>\u001b[39;00m\n",
      "\u001b[1;32m   2668\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m   2670\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n",
      "\u001b[0;32m-> 2671\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   2674\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/clasfi/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n",
      "\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n",
      "\u001b[1;32m     72\u001b[0m \n",
      "\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n",
      "\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/clasfi/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n",
      "\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n",
      "\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n",
      "\u001b[1;32m    478\u001b[0m     )\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9043, 2]"
     ]
    }
   ],
   "source": [
    "models_roc(X_train, y_train, X_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f027e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the results\n",
    "res = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'SVC', 'Gaussian Naive Bayes', 'K Neighbors'],\n",
    "    'Accuracy': [accuracy_score(y_test, logreg.predict(X_test)), \n",
    "                 accuracy_score(y_test, dtree.predict(X_test)), \n",
    "                 accuracy_score(y_test, rforest.predict(X_test)), \n",
    "                 accuracy_score(y_test, gbm.predict(X_test)), \n",
    "                 accuracy_score(y_test, svc.predict(X_test)), \n",
    "                 accuracy_score(y_test, gnb.predict(X_test)), \n",
    "                 accuracy_score(y_test, knn.predict(X_test))],\n",
    "    'ROC_AUC_Score': [roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, dtree.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, rforest.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, gbm.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, svc.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, gnb.predict_proba(X_test)[:, 1]), \n",
    "                      roc_auc_score(y_test, knn.predict_proba(X_test)[:, 1])]\n",
    "})\n",
    "\n",
    "# Sort the results by accuracy\n",
    "res = res.sort_values(by='ROC_AUC_Score', ascending=False)\n",
    "# Display the results\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
